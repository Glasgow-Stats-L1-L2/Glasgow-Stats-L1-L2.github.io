[["index.html", "Practical 4 - Transforming variables and further examining model assumptions 1 Introduction 1.1 Intended Learning Outcomes", " Practical 4 - Transforming variables and further examining model assumptions Megan Ruffle 1 Introduction 1.1 Intended Learning Outcomes fit linear models with transformed variables; produce residual plots and assess the assumptions of a linear model. "],["example-1---life-expectancy-log-transformation-on-x.html", " 2 Example 1 - life expectancy (log-transformation on x) 2.1 Statistical Analysis 2.2 Assumption Checking 2.3 Regression output", " 2 Example 1 - life expectancy (log-transformation on x) Rossman (1994) collected information on life expectancy in various countries of the world and the densities of people per television set and of people per physician in those countries. The data is available in the LifeExp.csv file. Remember you may need to reset your working directory and your data should be saved into that directory. How to read in your data life &lt;- read.csv(&quot;LifeExp.csv&quot;) In this practical, our focus is to identify how female life expectancy (Y , abbreviated to FLE) is related to the number of people per physician (x, abbreviated to PPP). (a) i. Create a scatterplot of FLE against PPP. Hint We can use the codeplot(). What variables do we want on our x and y axis? Solution plot(FLE ~ PPP, data = life) Look at your plot and pick the correct statement. There is no relationship between Female Life Expectancy and People per Phyisician There is an inverse relationship between Female Life Expectancy and People per Phyisician and as PPP increases, FLE decreases There is an inverse relationship between Female Life Expectancy and People per Phyisician and as PPP increases FLE increases As the relationship appears to be non-linear, we might want to apply a transformation to the predictor variable. Transforming the values of x might be the first thing to try if there is a non-linear monotonic (i.e. entirely non-increasing or entirely non-decreasing) trend in the data, and non-linearity is the only problem (i.e the model assumptions: independence, zero-mean, constant variance and normality should be met). What transformation should we apply here: LogarithmicSquare-rootNo transformation Create a new scatterplot of female life expectancy against the transformed PPP variable: Hint We can use the codeplot() again. Change x to be the log of your predictor variable. You may need to change the axis label too. Solution plot(FLE ~ log(PPP), data = life, xlab = &quot;log(PPP)&quot;) 2.1 Statistical Analysis The model for the relationship between FLE and log(PPE) is therefore: \\(Y_i = \\alpha + \\beta \\cdot log(x_i) + \\epsilon_i\\), where \\(\\epsilon_i \\sim N(0, \\sigma^2)\\) and \\(i = 1, . . . , 37.\\) (b) What type of model is this? Simple Linear RegressionMultiple RegressionNon-linear Regression Use the lm() function to fit this model to your plot: help(lm) Hint Use the help(lm) function to see what parameters you need within the function. Solution Model1 &lt;- lm(FLE ~ log(PPP), data = life) 2.2 Assumption Checking (c) i. Model assumptions can be assessed graphically by producing a plot of the residuals versus the fitted values and a normal probability plot (Q-Q plot) of the residuals. Hint Use the plot(rstandard()~fitted()) function for the residual plot and the code qqnorm for the Q-Q plot. Solution plot(rstandard(Model1) ~ fitted(Model1)) qqnorm(rstandard(Model1)) The residual vs fitted values plot shows that the points areare not fairly evenly scattered above and below themean linezero line, which suggests it isis not reasonable to assume that the random errors have mean equal to µzero. The vertical variation of the points seems to be small for small fitted values. However, there are also fewer points in this case. It would be preferable if moreless data were available. In the normal probability plot, we see that points dodo not exactly lie on diagonal line. This indicates that the Normality assumption maymay notbe satisfied. The independence of the random errors seemsdoes not seem reasonable since each point refers to a different country. 2.3 Regression output (d) i. Load the summary statistics: Solution summary(Model1) ## ## Call: ## lm(formula = FLE ~ log(PPP), data = life) ## ## Residuals: ## Min 1Q Median 3Q Max ## -9.065 -3.489 1.143 2.663 7.674 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 109.9498 3.6860 29.83 &lt; 2e-16 *** ## log(PPP) -5.4893 0.5036 -10.90 8.48e-13 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 4.286 on 35 degrees of freedom ## Multiple R-squared: 0.7724, Adjusted R-squared: 0.7659 ## F-statistic: 118.8 on 1 and 35 DF, p-value: 8.484e-13 Fill in the blanks in the regression equation with the calculated parameters to 2 decimal places: \\(FLE\\) = − \\(\\bigg(\\) \\(\\cdot\\) \\(log(PPP)\\bigg)\\) Interpret the parameters correctly and enter any numbers to 2 decimal places: This means the female life expectancy is seemsdoes not seem related to the number of people per physician. If log(PPP) increases by 1 unit, the expected female life expectancy increasesdecreases by . Using the created model predict the life expectancy if the number of people per physician is 4000, to 2 decimal places: Hint When predicting the value of the response for a new observation, we need to back transform the variable. \\(FLE\\) = − \\(\\bigg(\\) \\(\\cdot\\) \\(log(\\)\\()\\bigg)\\) = "],["example-2---car-stopping-power-transformation-on-y.html", " 3 Example 2 - Car stopping (power transformation on y) 3.1 Statistical Analysis 3.2 Assumption Checking 3.3 Regression output", " 3 Example 2 - Car stopping (power transformation on y) The stopping.csv file contains 63 observations of cars. In these observations, two variables were recorded, namely the speed of cars when the brakes were applied (in mile per hour) and the stopping. How to read in your data stopping &lt;- read.csv(&quot;Stopping.csv&quot;) (a) i. Create a scatterplot of Distance against Speed. Hint We can use the code plot(). What variables do we want on our x and y axis? Solution plot(Distance ~ Speed, data = stopping) Look at your plot and pick the correct statement. There is a no relationship between Stopping Distance and Speed There is an non-linear relationship between Stopping Distance and Speed and as Speed increases, Distance decreases TThere is an non-linear relationship between Stopping Distance and Speed and as Speed increases, Distance increases As the relationship appears to be non-linear, we might want to apply a transformation to one of the variables. What transformation should we apply here: Logarithmic to the predictorSquare-root to the responseNo transformation Create a new scatterplot of with the transformed data: Hint We can use the codeplot() again. Change Y to be the square root of your response variable. You may need to change the axis label too. Solution plot(sqrt(Distance) ~ Speed, data = stopping, ylab= &quot;Square root of Distance (in feet)&quot;) 3.1 Statistical Analysis The model for the relationship between Speed and sqrt(Distance) is therefore: \\(\\sqrt{Y_i} = \\alpha + \\beta x_i + \\epsilon_i\\), where \\(\\epsilon_i \\sim N(0, \\sigma^2)\\) and \\(i = 1, . . . , 63.\\) (b) What type of model is this? Simple Linear RegressionMultiple RegressionNon-linear Regression Use the lm() function to fit this model to your plot: help(lm) Hint Use the help(lm) function to see what parameters you need within the function. Solution Model1 &lt;- lm(sqrt(Distance) ~ Speed, data = stopping) 3.2 Assumption Checking (c) i. Model assumptions can be assessed graphically by producing a plot of the residuals versus the fitted values and a normal probability plot (Q-Q plot) of the residuals. Hint Use the plot(rstandard()~fitted()) function for the residual plot and the code qqnorm for the Q-Q plot. Solution plot(rstandard(Model1) ~ fitted(Model1)) qqnorm(rstandard(Model1)) The residual vs fitted values plot shows that the points areare not fairly evenly scattered above and below themean linezero line, which suggests it isis not reasonable to assume that the random errors have mean equal to µzero. In the normal probability plot, we see that points dodo not exactly lie on diagonal line. This indicates that the Normality assumption maymay notbe satisfied. This is not ideal but, on the positive side, the estimates of parameters will not be affected and hence we can still use the model to describe the relationship between variables and make predictions. 3.3 Regression output (d) i. Load the summary statistics: Solution summary(Model1) ## ## Call: ## lm(formula = sqrt(Distance) ~ Speed, data = stopping) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.4879 -0.5487 0.0098 0.5291 1.5545 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.918283 0.197406 4.652 1.82e-05 *** ## Speed 0.252568 0.009246 27.317 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.7193 on 61 degrees of freedom ## Multiple R-squared: 0.9244, Adjusted R-squared: 0.9232 ## F-statistic: 746.2 on 1 and 61 DF, p-value: &lt; 2.2e-16 Fill in the blanks in the regression equation with the calculated parameters to 3 decimal places: \\(\\sqrt{Distance}\\) = − \\(\\bigg(\\) \\(\\cdot\\) Speed \\(\\bigg)\\) Interpret the parameters correctly and enter any numbers to 2 decimal places: This means the square root of distance is PositivelyNegatively linearly related to speed. That is, as the speed increases by 1 MPH, the expected square root of distance increasesdecreases by feet. Using the created model predict the Stopping Distance if the Speed is 20MPH, to 2 decimal places: Hint When predicting the value of the response for a new observation, we need to back transform the transformed variable. \\(Distance = \\bigg(\\) + ( \\(\\cdot\\) ) \\(\\bigg) ^2\\) = feet. "],["example-3---mammal-weight-log-transformation-on-both-x-and-y.html", " 4 Example 3 - Mammal weight (log-transformation on both x and y)", " 4 Example 3 - Mammal weight (log-transformation on both x and y) This data was collected to analyse the relationship between constitutional and ecological factors and sleeping (dreaming and non-dreaming) in mammals. Constitutional variables included life span, body weight, brain weight and gestation time. Ecological variables included severity of predation, safety of sleeping place and overall danger and were inferred from field observations in the literature. We are interested in finding out if how body weight and brain weight are related. Import your dataset and get familiar with the data within it. (a) i. Produce a scatterplot of body weight versus brain weight. Solution mammals &lt;- read.csv(&quot;MammalWeight.csv&quot;) plot(brain_wt ~ body_wt, data = mammals, xlab = &quot;Body Weight (kg)&quot;, ylab = &quot;Brain Weight (g)&quot;) Perform a logtransformation on both variables and produce the scatterplot again with the new variables. Solution mammals &lt;- read.csv(&quot;MammalWeight.csv&quot;) plot(log(brain_wt) ~ log(body_wt), data = mammals, xlab = &quot;Log(Body Weight)&quot;, ylab = &quot;Log(Brain Weight)&quot;) Which of the scatterplots seems to show a linear relationship? TransformedUntransformed (b) i. Fit a simple linear regression model to describe the relationship between log(body weight) and log(brain weight). Solution Model1 &lt;- lm(log(brain_wt) ~ log(body_wt), data = mammals) Produce the residual plots and find the coefficient of determination, \\(R^2\\) to examine the fit of the model. Solution plot(rstandard(Model1) ~ fitted(Model1)) qqnorm(rstandard(Model1)) summary(Model1) ## ## Call: ## lm(formula = log(brain_wt) ~ log(body_wt), data = mammals) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.71550 -0.49228 -0.06162 0.43597 1.94829 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.13479 0.09604 22.23 &lt;2e-16 *** ## log(body_wt) 0.75169 0.02846 26.41 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.6943 on 60 degrees of freedom ## Multiple R-squared: 0.9208, Adjusted R-squared: 0.9195 ## F-statistic: 697.4 on 1 and 60 DF, p-value: &lt; 2.2e-16 Pick the correct interpretation of the model: The R-Squared value is too low and that indicates the model isn't a good fit without needing to look at the residual plots The R-Squared value is high and both residual plots show the assumptions are met. Model1 is a well-fitting appropriate model The R-Squared value is high and but the residual plots show the assumptions are not met. Model1 is therefore not an appropriate model Interpret the parameters correctly and enter any numbers to 4 decimal places: The coefficient of log(body weight) is means as the log of the body weight increases by 1, the expected log of the brain weight increasesdecreases by . Using the created model predict the brain weight of an animal if the body weight is 350kg, to 3 decimal places: Hint When predicting the value of the response for a new observation, we need to back transform the transformed response variable. Brain weight = \\(exp\\bigg(\\) + ( \\(\\cdot\\) log()) \\(\\bigg)\\) = g. "],["exercise-1---transformation-of-predictors.html", " 5 Exercise 1 - Transformation of Predictors", " 5 Exercise 1 - Transformation of Predictors The data frame SIMDATAXT contains simulated data for the response, y, and predictors, \\(x_1\\), \\(x_2\\), and \\(x_3\\). We will apply appropriate transformations to \\(x_1\\), \\(x_1\\), and\\(x_1\\) to linearise the relationships between the response and predictors one at a time. Remember that when you use operators such as \\(\\text{+, -, ^, *, }\\) you must use the identity function, \\(I()\\) , to inhibit the interpretation of your formula operator as an arithmetic operator (a) Below are some questions to help you follow the right steps. Starting with \\(x_1\\): Does the plot of \\(x_1\\) against \\(Y\\) appear linear? YesNo Which transformation produces a scatterplot that seem to present a linear relationship? Square-root xinverse of x (1/x)x squaredNo transformation Do both the residual plots, as well as the and the coefficient of determination, \\(R^2\\) support this transformed model? If no, go back to ii. Solution # Plot of x1 against Y plot(y ~ x1, data = SIMDATAXT) # This appears non-linear # Plot of data with a square root transformation plot(y ~ I(x1^0.5), data = SIMDATAXT) # This appears linear # Define your linear model Model1 &lt;- lm(y ~ I(x1^0.5), data = SIMDATAXT) # Get the residual plots plot(rstandard(Model1) ~ fitted(Model1)) qqnorm(rstandard(Model1)) #Get the coefficient of determination, R-squared summary(Model1) ## ## Call: ## lm(formula = y ~ I(x1^0.5), data = SIMDATAXT) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.6885 -0.8014 -0.0047 0.6989 3.4644 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.44101 0.17178 -2.567 0.011 * ## I(x1^0.5) 1.07688 0.02769 38.890 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.083 on 196 degrees of freedom ## (2 observations deleted due to missingness) ## Multiple R-squared: 0.8853, Adjusted R-squared: 0.8847 ## F-statistic: 1512 on 1 and 196 DF, p-value: &lt; 2.2e-16 # 0.8853 is high enough to indicate a good fit and the assumpions here are met. (b) Repeat for \\(x_2\\) Solution # Plot of x2 against Y plot(y ~ x2, data = SIMDATAXT) # This appears non-linear # Plot of data with a squared transformation plot(y ~ I(x2^2), data = SIMDATAXT) # This appears linear # Define your linear model Model1 &lt;- lm(y ~ I(x2^2), data = SIMDATAXT) # Get the residual plots plot(rstandard(Model1) ~ fitted(Model1)) qqnorm(rstandard(Model1)) #Get the coefficient of determination, R-squared summary(Model1) ## ## Call: ## lm(formula = y ~ I(x2^2), data = SIMDATAXT) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.5088 -0.7309 -0.0139 0.7235 3.4310 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.3336 0.1679 -1.987 0.0482 * ## I(x2^2) 1.0619 0.0272 39.040 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.087 on 198 degrees of freedom ## Multiple R-squared: 0.885, Adjusted R-squared: 0.8844 ## F-statistic: 1524 on 1 and 198 DF, p-value: &lt; 2.2e-16 # 0.885 is high enough to indicate a good fit and the assumpions here are met. (c) Repeat for \\(x_3\\) Solution # Plot of x3 against Y plot(y ~ x3, data = SIMDATAXT) # This appears non-linear # Plot of data with an inverse transformation plot(y ~ I(x3^-1), data = SIMDATAXT) # This appears linear # Define your linear model Model1 &lt;- lm(y ~ I(x3^-1), data = SIMDATAXT) # Get the residual plots plot(rstandard(Model1) ~ fitted(Model1)) qqnorm(rstandard(Model1)) #Get the coefficient of determination, R-squared summary(Model1) ## ## Call: ## lm(formula = y ~ I(x3^-1), data = SIMDATAXT) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.5088 -0.7309 -0.0139 0.7235 3.4310 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.3336 0.1679 -1.987 0.0482 * ## I(x3^-1) 1.0619 0.0272 39.040 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.087 on 198 degrees of freedom ## Multiple R-squared: 0.885, Adjusted R-squared: 0.8844 ## F-statistic: 1524 on 1 and 198 DF, p-value: &lt; 2.2e-16 # 0.885 is high enough to indicate a good fit and the assumpions here are met. (d) Which selection of variables therefore needed to be transformed? x1x2x3x1, x2x1, x3x2, x3x1, x2, x3none of the above "],["exercise-2.html", " 6 Exercise 2 6.1 Exercise 2 Part 1 - Transforming Y with ln 6.2 Exercise 2 Part 2 - Transforming Y with a reciprical", " 6 Exercise 2 6.1 Exercise 2 Part 1 - Transforming Y with ln Note that the default understanding of log in R is \\(log_e\\) = ln = log. (a) Perform analysis the data frame SIMDATAST to create and display six graphs using a 2 by 3 layout. Produce a scatterplot of \\(y_1\\) versus \\(x_1\\). Solution Code # Begin by setting up the 2x3 grid par(mfrow = c(2, 3)) # Plot y1 vs x1 plot(y1 ~ x1, data = SIMDATAST) Plot the residuals versus fits for the model created by regressing \\(y_1\\) on \\(x_1\\) (call this model modx1). Based on the first two graphs, does a logarithmic transformation for the response variable make sense? Solution Code # Define the model modx1 &lt;- lm(y1 ~ x1, data = SIMDATAST) # Plot the residual graphs plot(modx1, which = c(1,2)) #This plot function will produce many analytical graphs so using c(1,2) selects that you want the fitted residual plot and the Q-Q plot as they are the first 2 it produces. (iii) In the second row of graphs, create a scatterplot of \\(ln(y_1\\)) versus \\(x_1\\). Solution Code # Plot y1 vs ln(x1) plot(log(y1) ~ x1, data = SIMDATAST) (iv) Create a plot of the residuals versus the fits for the model and the Q-Q normal plot for log(\\(y_1\\)) ~ \\(x_1\\). Solution Code # Use the plot function: plot(lm(log(y1) ~ x1, data = SIMDATAST), which = c(1,2)) # when Par is run along with the rest of this code it will put the 6 graphs in the grid. Solution Plot Based on the second row of graphs, do the assumptions for the normal error model seem to be satisfied for the model log(\\(y_1\\)) ~ \\(x_1\\)? YesNo 6.2 Exercise 2 Part 2 - Transforming Y with a reciprical (a) Perform analysis the data frame SIMDATAST to create and display six graphs using a 2 by 3 layout. Produce a scatterplot of \\(y_2\\) versus \\(x_2\\). Solution Code # Begin by setting up the 2x3 grid par(mfrow = c(2, 3)) # Plot y1 vs x1 plot(y2 ~ x2, data = SIMDATAST) Plot the residuals versus fits for the model created by regressing \\(y_2\\) on \\(x_2\\) (call this model modx2). Solution Code # Define the model modx2 &lt;- lm(y2 ~ x2, data = SIMDATAST) # Plot the residual graphs plot(modx2, which = c(1,2)) #This plot function will produce many analytical graphs so using c(1,2) selects that you want the fitted residual plot and the Q-Q plot as they are the first 2 it produces. Based on the first two graphs, does a reciprocal transformation for the response variable make sense? YesNo In the second row of graphs, create a scatterplot of \\(y_2^{-1}\\) versus\\(x_2\\). Solution Code # Plot y1 vs ln(x1) plot((y2)^-1 ~ x2, data = SIMDATAST) Create a plot of the residuals versus the fits and the Q-Q normal plot for \\(y_2^{-1} \\sim x_2\\). Solution Code # Use the plot function: plot(lm((y2)^-1 ~ x2, data = SIMDATAST), which = c(1,2)) # when Par is run along with the rest of this code it will put the 6 graphs in the grid. Solution Plot Based on the second row of graphs, do the assumptions for the normal error model seem to be satisfied for the model \\(y_2^{-1} \\sim x_2\\)? YesNo "],["exercise-3---transformation-of-the-response-and-predicator.html", " 7 Exercise 3 - Transformation of the response and predicator", " 7 Exercise 3 - Transformation of the response and predicator At times it will be necessary to transform both the response and the predictor. Using the SIMDATAST data set produce an ouput of your graphs in a 2 rows x 3 columns grid: (a) i. Plot \\(y_1\\) against \\(x_3\\) Define the model for \\(y_1\\) against \\(x_3\\) and create the residual vs fitted values plot. Log transform the response variable and produce a new scatterplot. Define the model for \\(log(y_1)\\) against \\(x_3\\) and create a residual vs fitted values plot. Square-root predictor and plot a scatterplot of \\(log(y_1)\\) against \\(\\sqrt{x_3}\\) Define the model for \\(log(y_1)\\) against \\(\\sqrt{x_3}\\) and create a residual vs fitted values plot. Solution code # create 2 rows x 3 columns grid par(mfrow = c(2, 3)) # plot y vs x3 plot(y1 ~ x3, data = SIMDATAST,main=&quot;Scatterplot of y1~x3&quot;) # define model for log transformed response y1 vs x3 mod1 &lt;- lm(y1 ~ x3, data = SIMDATAST) # you can choose to add the model line to the plot with abline(mod1) # residual plot for mod1 plot(mod1, which = 1, main = &quot;Residuals vs Fitted value for y1~x3&quot;) # plot of log transformed y against x3 plot(log(y1) ~ x3, data = SIMDATAST, main = &quot;Scatterplot of log(y1)~x3&quot;) # define model for log transformed response y1 vs x3 mod2 &lt;- lm(log(y1) ~ x3, data = SIMDATAST) # optionally add abline(mod2) to the plot # residual plot for mod2 plot(rstandard(mod2) ~ fitted(mod2), main=&quot;Residuals vs Fitted value for log(y1)~x3&quot;) # optional to add abline(h=0,lty=3) to the plot # plot of log transformed y against sqrt(x3) plot(log(y1) ~ I(x3^0.5), data = SIMDATAST, main = &quot;Scatterplot of log(y1)~sqrt(x3)&quot;) mod3 &lt;- lm(log(y1) ~ I(x3^.5), data = SIMDATAST) # define model for log transformed response y1 vs sqrt(x3) #optional to add abline(mod3) to the plot # residual plot for mod3 plot(rstandard(mod3) ~ fitted(mod3), main=&quot;Residuals vs fitted of log(y1)~sqrt(x3)&quot;) # optional to add abline(h=0,lty=3) to the plot "],["exercise-4---transformation-of-the-response-and-predicator.html", " 8 Exercise 4 - Transformation of the response and predicator", " 8 Exercise 4 - Transformation of the response and predicator The Animals data set which pertains to Brain and Body Weights for 28 Species. You can get this data set using the library(Mass) In this dataset there are three outliers which are the dinosaurs. (a) Sort the data by body and remove the last three dinosaur elements using the following code: Sorting your data SA &lt;- Animals[order(Animals$body), ] #sorted by body weight NoDINO &lt;- SA[-c(28:26), ] #remove dinosaurs Now treating the data as we done in the previous exercise transform both the response and predictor: (b) Define a linear model for the transformed response and transformed predictor . Solution model1 &lt;- lm(log(brain) ~ log(body), data = NoDINO) (c) Use the function coef() to answer the below questions: Coef function solution coef(model1) ## (Intercept) log(body) ## 2.1504121 0.7522607 i. What is the predicted brain weight of the jaguar whose weight is listed as 100 kg? Log(Brain weight) = + ( \\(\\cdot\\) log()) = . This must be back transformed to get the units of original brain measurement (grams). Brain weight = \\(exp(\\)\\()\\) = g Solution Log(Brain weight) = \\(2.1504\\) + (\\(0.7523\\) \\(\\cdot\\) \\(log(100) = 5.6149\\). Back-transforming with exponential menas Brain weight = \\(exp(5.6149)\\) = \\(274.48\\)g ii. If said jaguar were to increase its weight by 10%, what would the expected increase in brain weight be? \"With the coefficient of , an increase in body weight of 1% would lead to % increase in brain weight. * = g\" Solution \"With the coefficient of \\(0.7523\\), an increase in body weight of 1% would lead to \\(7.523\\)% increase in brain weight. so \\(1.07523 * 274.48\\) = \\(295.0634\\)g "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
